% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/rgcca.R
\name{rgcca}
\alias{rgcca}
\title{Regularized (or Sparse) Generalized Canonical Correlation Analysis (R/SGCCA)}
\usage{
rgcca(
  blocks,
  type = "rgcca",
  scale = TRUE,
  scale_block = TRUE,
  connection = matrix(1, length(blocks), length(blocks)) - diag(length(blocks)),
  scheme = "factorial",
  ncomp = rep(1, length(blocks)),
  tau = rep(1, length(blocks)),
  sparsity = rep(1, length(blocks)),
  init = "svd",
  bias = TRUE,
  tol = 1e-08,
  response = NULL,
  superblock = FALSE,
  method = "nipals",
  verbose = FALSE,
  quiet = TRUE
)
}
\arguments{
\item{blocks}{A list that contains the J blocks of variables X1, X2, ..., XJ. 
Block j is a matrix of dimension $n x p_j$ where $p_j$ is the number of 
variables in X_j.}

\item{type}{A character giving the type of analysis: rgcca, sgcca, pca, 
pls, cca, ifa, ra, cpca-w, gcca, hpca, maxbet-b, maxbet, maxdiff-b,maxdiff,
 maxvar-a, maxvar-b, maxvar, niles, r-maxvar, rcon-pca, ridge-gca, sabscor,
 ssqcor, ssqcor, ssqcov-1, ssqcov-2, ssqcov,  sum-pca, sumcor, sumcov-1, 
 sumcov-2, sumcov, sabscov, plspm}

\item{scale}{A logical value indicating if each block is normalised and divided by the square root of its number of variables and then divided by the square root of its number of variables.}

\item{scale_block}{A logical value indicating if each block have the same weight in the RGCCA analysis. Otherwise, the weight of each block depends on the number of variables of the block}

\item{connection}{A symmetric matrix (J*J) that describes the relationships 
between blocks. Two values are accepted : '1' for a connection between two 
blocks, or '0' otherwise.}

\item{scheme}{A character or a function giving the link function for 
covariance maximization among "horst" (the identity function), "factorial"
 (the squared values), "centroid" (the absolute values). Only, the horst 
 scheme penalizes structural negative correlation. The factorial scheme 
 discriminates more strongly the blocks than the centroid one.}

\item{ncomp}{A vector of 1*J integers giving the number of component for 
each blocks}

\item{tau}{Either a 1*J vector or a \eqn{\mathrm{max}(ncomp) \times J} matrix containing the values 
of the regularization parameters (default: tau = 1, for each block and each dimension). Tau varies from 0 (maximizing the correlation) to 1 (maximizing the covariance).
If tau = "optimal" the regularization paramaters are estimated for each block and each dimension using the Schafer and Strimmer (2005)
analytical formula . If tau is a \eqn{1\times J} vector, tau[j] is identical across the dimensions of block \eqn{\mathbf{X}_j}. 
If tau is a matrix, tau[k, j] is associated with \eqn{\mathbf{X}_{jk}} (\eqn{k}th residual matrix for block \eqn{j}). It can be estimated by using \link{rgcca_permutation}.}

\item{sparsity}{Either a \eqn{1*J} vector or a \eqn{max(ncomp) * J} matrix 
encoding the L1 constraints applied to the outer weight vectors. The amount 
of sparsity varies between \eqn{1/sqrt(p_j)} and 1 (larger values of sparsity 
correspond to less penalization). If sparsity is a vector, L1-penalties are 
the same for all the weights corresponding to the same block but different 
components: 
\deqn{for all h, |a_{j,h}|_{L_1} \le c_1[j] \sqrt{p_j},}
with \eqn{p_j} the number of variables of \eqn{X_j}.
If sparsity is a matrix, each row \eqn{h} defines the constraints applied to 
the weights corresponding to components \eqn{h}:
\deqn{for all h, |a_{j,h}|_{L_1} \le c_1[h,j] \sqrt{p_j}.} It can be 
estimated by using \link{rgcca_permutation}.}

\item{init}{A character giving the mode of initialization to use in the algorithm. The alternatives are either by Singular Value Decompostion ("svd") or random ("random") (default: "svd").}

\item{bias}{A logical value for biaised (\eqn{1/n}) or unbiaised (\eqn{1/(n-1)}) estimator of the var/cov (default: bias = TRUE).}

\item{tol}{An integer giving the value for stopping the algorithm convergence.}

\item{response}{An integer giving the position of the response block within 
the blocks (activates the supervised mode).}

\item{superblock}{Boolean indicating the presence of the superblock. 
Default = TRUE}

\item{method}{Either a character corresponding to the used method 
("complete","knn","em","sem") or a function taking a list of J blocks (A) as 
only parameter and returning the imputed list. 
\itemize{
\item{\code{"mean"}}{ corresponds to an imputation by the colmeans}
\item{\code{"complete"}}{ corresponds to run RGCCA only on the complete subjects (subjects with missing data are removed)}
\item{\code{"nipals"}}{ corresponds to run RGCCA on all available data (NIPALS algorithm)}
\item{\code{"em"}}{ corresponds to impute the data with EM-type algorithms}
\item{\code{"sem"}}{ corresponds to impute the data with EM-type algorithms with superblock approach}
\item{\code{"knn1"}}{ corresponds to impute the data with the 1-Nearest Neighbor. 1 can be replace by another number (such as knn3) to impute with the 3-Nearest Neighbors.}}}

\item{verbose}{A logical value indicating if the progress of the analysis will be reported while computing.}

\item{quiet}{A logical value indicating if it should not print warnings}
}
\value{
A RGCCA object

\item{Y}{A list of \eqn{J} elements. Each element of the list \eqn{Y} 
is a matrix that contains the RGCCA block components for the corresponding 
block.}

\item{a}{A list of \eqn{J} elements. Each element of the list \eqn{a} 
is a matrix of block weight vectors for the corresponding block.}

\item{astar}{A list of \eqn{J} elements. Each element of astar is a 
matrix defined as Y[[j]][, h] = A[[j]]\%*\%astar[[j]][, h].}

\item{tau}{Either a 1*J vector or a \eqn{\mathrm{max}(ncomp) \times J} 
matrix containing the values of the regularization parameters. tau varies 
from 0 (maximizing the correlation) to 1 (maximizing the covariance). 
If tau = "optimal" the regularization paramaters are estimated for each 
block and each dimension using the Schafer and Strimmer (2005) analytical 
formula. If tau is a \eqn{1\times J} vector, tau[j] is identical across the 
dimensions of block \eqn{\mathbf{X}_j}. If tau is a matrix, tau[k, j] is 
associated with \eqn{\mathbf{X}_{jk}} (\eqn{k}th residual matrix for 
block \eqn{j}). tau can be also estimated using \link{rgcca_permutation}.}

\item{crit}{A list of vector of length max(ncomp). Each vector of 
the list is related to one specific deflation stage and reports the values 
of the criterion for this stage across iterations.}

\item{primal_dual}{A \eqn{1 \times J} vector that contains the 
formulation ("primal" or "dual") applied to each of the \eqn{J} blocks 
within the RGCCA alogrithm.}

\item{AVE}{A list of numerical values giving the indicators of model 
quality based on the Average Variance Explained (AVE): AVE(for each block), 
AVE(outer model), AVE(inner model).}

\item{A}{A list of matrices giving the \eqn{J} blocks of variables 
\eqn{\mathbf{X_1}, \mathbf{X_2}, ..., \mathbf{X_J}.}
These matrices, used in the calculations, are imputed if an imputation 
method is selected.}

\item{call}{Call of the function}
}
\description{
RGCCA is a generalization of regularized canonical correlation analysis to 
three or more sets of variables. SGCCA extends RGCCA to address the issue of 
variable selection
}
\details{
Given J matrices \eqn{\mathbf{X_1}, \mathbf{X_2}, ..., \mathbf{X_J}} that 
represent \eqn{J} sets of variables observed on the same set of \eqn{n} 
individuals. The matrices \eqn{\mathbf{X_1}, \mathbf{X_2}, ..., \mathbf{X_J}} 
must have the same number of rows, but may (and usually will) have different 
numbers of columns. The aim of RGCCA is to study the relationships between 
these \eqn{J} blocks of variables. It constitutes a general framework for 
many multi-block data analysis methods (see Tenenhaus and Tenenhaus, 2011 ; 
Tenenhaus et al. 2017). It combines the power of multi-block data analysis 
methods (maximization of well identified criteria) and the flexibility of 
PLS path modeling (the researcher decides which blocks are connected and 
which are not). Hence, the use of RGCCA requires the construction (user 
specified) of a design matrix, (\eqn{\mathbf{C}}), that characterizes the 
connections between blocks. Elements of the (symmetric) design matrix 
\eqn{\mathbf{C} = (c_{jk})} are positive (and usually equal to 1 if block 
\eqn{j} and block \eqn{k} are connected, and 0 otherwise). The function 
rgcca() implements a monotone global convergent algorithm - i.e. the 
bounded criteria to be maximized increases at each step of the iterative 
procedure and hits, at convergence a stationary point of the RGCCA 
optimization problem. Moreover, depending on the dimensionality of each 
block \eqn{\mathbf{X}_j}, \eqn{j = 1, \ldots, J}, the primal (when 
\eqn{n > p_j}) algorithm or the dual (when \eqn{n < p_j}) algorithm is used 
(see Tenenhaus et al. 2015). At last, a deflation strategy is used to compute 
several RGCCA block components (specified by ncomp) for each block. Block 
components of each block are guaranteed to be orthogonal. The so-called 
symmetric deflation is implemented (i.e. each block is deflated with respect 
to its own component). It should be noted that the numbers of components 
per block can differ from one block to another. SGCCA extends RGCCA to 
address the issue of variable selection (Tenenhaus et al, 2014). 
Specifically, RGCCA is combined with an L1-penalty that gives rise to Sparse 
GCCA (SGCCA). The SGCCA algorithm is very similar to the RGCCA algorithm and 
keeps the same convergence properties (i.e. the bounded criteria to be 
maximized increases at each step of the iterative procedure and hits at 
convergence a stationary point). Moreover, using a deflation strategy, 
sgcca() enables the computation of several SGCCA orthogonal block components 
(specified by ncomp) for each block.  
The rgcca() function can handle missing values using a NIPALS type algorithm 
(non-linear iterative partial least squares algorithm) described in 
(Tenenhaus et al, 2005).
}
\examples{
####################
# Example 1: RGCCA #
####################
# Create the dataset
data(Russett)
blocks = list(agriculture = Russett[, seq(3)], 
    industry = Russett[, 4:5],
    politic = Russett[, 6:11])

# Blocks are fully connected, factorial scheme and tau =1 for all blocks is 
# used by default
fit.rgcca = rgcca(blocks=blocks, type = "rgcca", connection = 1-diag(3), 
                  scheme = "factorial", tau = rep(1, 3))
print(fit.rgcca)
plot(fit.rgcca, type = "weight", block = 3)
politic = as.vector(apply(Russett[, 9:11], 1, which.max)) 
plot(fit.rgcca, type = "ind", block = 1:2, comp = rep(1, 2), resp = politic)

############################################
# Example 2: RGCCA and multiple components #
############################################
fit.rgcca = rgcca(blocks, type = "rgcca", connection = C, superblock = FALSE, 
tau = rep(1, 3), ncomp = c(2, 2, 2), scheme = "factorial", verbose = TRUE)

politic = as.vector(apply(Russett[, 9:11], 1, which.max)) 
plot(fit.rgcca, type = "ind", block = 1:2, comp = rep(1, 2), resp = politic)

plot(fit.rgcca, type = "ave")
plot(fit.rgcca, type = "network")
plot(fit.rgcca, type = "weight", block = 1)
plot(fit.rgcca, type = "cor")

##################################
# Example 3: Sparse GCCA (SGCCA) #
##################################

# Tune the model to find the best sparsity coefficients (all the blocs are 
# connected together)
perm = rgcca_permutation(blocks, n_cores = 1, par_type = "sparsity", 
 n_perms = 10)
print(perm)
plot(perm)

res_sgcca = rgcca(blocks, sparsity = perm$bestpenalties)
plot(res_sgcca, type = "network")
plot(res_sgcca, type = "ave")

# Select the most significant variables
b = bootstrap(res_sgcca, n_cores = 1, n_boot = 100)
plot(b, n_cores = 1)

##############################
# Example 3: Supervised mode #
##############################
# Tune the model for explaining the politic block (politic connected to the 
# two other blocks)
cv = rgcca_cv(blocks, response = 3, ncomp = 2, n_cores = 1)
print(cv)
plot(cv)

res_rgcca = rgcca(blocks, response = 3, ncomp = 2, tau = cv$bestpenalties)
plot(res_rgcca, type = "both")

b = bootstrap(res_rgcca, n_cores = 1, n_boot = 10)
plot(b, n_cores = 1)

##########################
# Example 4: Sparse GCCA #
##########################


}
\references{
Tenenhaus M., Tenenhaus A. and Groenen P. J. (2017). Regularized 
generalized canonical correlation analysis: a framework for sequential 
multiblock component methods. Psychometrika, 82(3), 737-777.

Tenenhaus A., Philippe C. and Frouin, V. (2015). Kernel 
generalized canonical correlation analysis. Computational Statistics and 
Data Analysis, 90, 114-131.

Tenenhaus A., Philippe C., Guillemot V., Le Cao K. A., Grill J., 
and Frouin V. (2014). Variable selection for generalized canonical 
correlation analysis. Biostatistics, 15(3), 569-583.

Tenenhaus A. and Tenenhaus M., (2011). Regularized Generalized 
Canonical Correlation Analysis, Psychometrika, Vol. 76, Nr 2, pp 257-284.

Schafer J. and Strimmer K. (2005). A shrinkage approach to 
large-scale covariance matrix estimation and implications for functional 
genomics. Statist. Appl. Genet. Mol. Biol. 4:32.

Tenenhaus A., Philippe C., Guillemot V., Le Cao K. A., Grill J. 
and Frouin, V., Variable selection for generalized canonical correlation 
analysis, Biostatistics, vol. 15, no. 3, pp. 569-583, 2014.
}
\seealso{
\code{\link[RGCCA]{plot.rgcca}}, \code{\link[RGCCA]{print.rgcca}},
\code{\link[RGCCA]{rgcca_cv_k}},
\code{\link[RGCCA]{rgcca_permutation}}
\code{\link[RGCCA]{rgcca_predict}}
}
